# TestNeiron

Обновлённая версия эксперимента по SAC для управления роботом из пиксельного ввода.

## Основное
- `telega.py` содержит две среды: старая `RobotEnv` (по координатам) и новая `RobotVisionEnv`, которая возвращает стек из 64x64 серых кадров камеры + проприоцепцию (sin/cos yaw).
- Добавлен пиксельный агент `VisionSACAgent` с компактным CNN-энкодером (NatureCNN) и frame stacking / frame skipping.
- Функция `train_pixel_sac` запускает обучение на изображениях (по умолчанию без GUI). Графики сохраняются в `telega_pixel_rewards.png`, веса — в `telega_pixel_agent.pt`.
- Скрипт `telegafiin.py` отображает работу обученной пиксельной политики.

## Запуск
```
python telega.py        # старт пиксельного обучения (настройки в __main__)
python telegafiin.py    # демонстрация сохранённой модели
```

## Нужен ли Gymnasium?
Текущее окружение реализовано «вручную» на PyBullet и не использует Gymnasium API. Это упрощает зависимости и ускоряет старт: скрипты работают без дополнительных обёрток, а обучение и демонстрация идут через встроенные функции (`train_pixel_sac`, `VisionSACAgent`). Добавлять Gymnasium имеет смысл только если планируется миграция на Stable-Baselines3 или другую библиотеку, требующую стандартный интерфейс — тогда среду можно обернуть в `gymnasium.Env` или реализовать адаптер, чтобы использовать готовые политики и логгеры.
